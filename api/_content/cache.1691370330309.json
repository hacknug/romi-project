{"generatedAt":1691370348081,"generateTime":481,"contents":[{"_path":"/","_dir":"","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Home","description":"","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"robotics-for-microfarms-develops-open-technologies-to-assist-organic-diversified-vegetable-farmers"},"children":[{"type":"element","tag":"span","props":{"class":"block max-w-5xl"},"children":[{"type":"text","value":"Robotics for Microfarms develops open technologies to assist organic, diversified, vegetable farmers."}]}]},{"type":"element","tag":"base-section","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:header":""},"children":[{"type":"element","tag":"h2","props":{"id":"tools"},"children":[{"type":"text","value":"Tools"}]}]},{"type":"element","tag":"section-grid","props":{"query":"/tools"},"children":[]}]},{"type":"element","tag":"base-section","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:header":""},"children":[{"type":"element","tag":"h2","props":{"id":"research"},"children":[{"type":"text","value":"Research"}]}]},{"type":"element","tag":"section-grid","props":{"query":"/research"},"children":[]}]},{"type":"element","tag":"base-section","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:header":""},"children":[{"type":"element","tag":"h2","props":{"id":"what-we-do"},"children":[{"type":"text","value":"What we do"}]}]},{"type":"element","tag":"section-split-hero","props":{"class":"bg-[url(/assets/tools/weeding/1-rover.jpg)]"},"children":[{"type":"element","tag":"template","props":{"v-slot:right":""},"children":[{"type":"element","tag":"base-card","props":{},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"ROMI is a four-year Europe-funded research project committed to promote a sustainable, local, and human-scale agriculture. It is developing an affordable, multipurpose platform adapted to support organic and polyculture market-garden farms."}]}]}]}]},{"type":"element","tag":"section-split-hero","props":{"class":"!bg-center xl:!bg-right bg-[url(/assets/home/project.jpg)]"},"children":[{"type":"element","tag":"template","props":{"v-slot:left":""},"children":[{"type":"element","tag":"base-card","props":{},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The platform constitutes robotic tools, research, data and shared documentation and aims to help farming communities increase their production and improve their working conditions."}]}]}]}]},{"type":"element","tag":"section-split-hero","props":{"class":"bg-[url(/assets/home/robotic-tools.jpg)]"},"children":[{"type":"element","tag":"template","props":{"v-slot:right":""},"children":[{"type":"element","tag":"base-card","props":{},"children":[{"type":"element","tag":"h2","props":{"id":"robotic-tools"},"children":[{"type":"text","value":"Robotic tools"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Open-source robotic tools can assist farmers in completing physically demanding or tedious tasks and can help with planning complex planting. Over four years, ROMI will work on the development of three robotic tools: a mechanical weeding robot, an aerial robot for crop monitoring and a 3D scanner for phenotyping in indoor and outdoor environments."}]}]}]}]},{"type":"element","tag":"section-split-hero","props":{"class":"bg-[url(/assets/home/field-studies.jpg)]"},"children":[{"type":"element","tag":"template","props":{"v-slot:left":""},"children":[{"type":"element","tag":"base-card","props":{},"children":[{"type":"element","tag":"h2","props":{"id":"field-studies"},"children":[{"type":"text","value":"Field studies"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Undertaking research directly in the field means ROMI can develop with the expertise of professional farmers. The efficiency and usability of robotic tools are tested across four seasons at two core sites: Chatelain Maraîchage near Paris and at Valldaura Self-sufficiency Labs near Barcelona. Additional community sites may be used for research as the project develops."}]}]}]}]},{"type":"element","tag":"section-split-hero","props":{"class":"bg-[url(/assets/home/phenotiping-and-data-science.jpg)]"},"children":[{"type":"element","tag":"template","props":{"v-slot:right":""},"children":[{"type":"element","tag":"base-card","props":{},"children":[{"type":"element","tag":"h2","props":{"id":"phenotyping-and-data-science"},"children":[{"type":"text","value":"Phenotyping and data science"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"ROMI is working on advanced 3D plant analysis and modelling techniques for indoor and in-field data acquisition. Collecting and analysing data can aid in the development of dashboards that can help monitor the status of farms and provide situated plant data for agronomy. ROMI is working with novel adaptive learning techniques to deal with unexpected situations."}]}]}]}]},{"type":"element","tag":"section-split-hero","props":{"class":"bg-[url(/assets/home/farming-communities.jpg)]"},"children":[{"type":"element","tag":"template","props":{"v-slot:left":""},"children":[{"type":"element","tag":"base-card","props":{},"children":[{"type":"element","tag":"h2","props":{"id":"farming-communities"},"children":[{"type":"text","value":"Farming communities"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"A new generation of farmers are starting small innovative market gardens in rural, peri-urban and urban areas across Europe. These farms often grow polycultures of up to 100 different varieties per year on small surfaces between 0.01 to 5 hectares. Polyculture and organic microfarms are proving to be highly productive, sustainable and economical, yet some of the on-the-ground experiences of farming communities are still unknown. ROMI aims to develop a better understanding of this emerging field through research, events and the development of specialised techniques and tools."}]}]}]}]},{"type":"element","tag":"base-card","props":{"class":"p-4 !rounded-3xl"},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"text","value":"  "},{"type":"element","tag":"div","props":{"className":["aspect-w-16","aspect-h-10","rounded-xl","overflow-hidden","isolate"]},"children":[{"type":"text","value":"\n    "},{"type":"text","value":"\n    "},{"type":"element","tag":"iframe","props":{"frameBorder":"0","allowFullScreen":true,"src":"https://umap.openstreetmap.fr/en/map/vegetable-microfarms-in-europe_224167?scaleControl=false&miniMap=false&scrollWheelZoom=false&zoomControl=true&allowEdit=false&moreControl=false&searchControl=false&tilelayersControl=false&embedControl=false&datalayersControl=false&captionBar=false#4/53/10"},"children":[]},{"type":"text","value":"\n  "}]}]}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:1.index.md","_source":"content","_file":"1.index.md","_extension":"md"},{"_path":"/tools","_dir":"","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Tools","description":"","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":""},"children":[{"type":"element","tag":"binding","props":{"value":"$doc.title"},"children":[]}]},{"type":"element","tag":"base-section","props":{},"children":[{"type":"element","tag":"section-grid","props":{"query":"/tools"},"children":[]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:2.tools:0.index.md","_source":"content","_file":"2.tools/0.index.md","_extension":"md"},{"_path":"/tools/plant-phenotyping","_dir":"tools","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"The Plant Imager","description":"The ROMI Imager performs a full 3D analysis of plants. It combines an imaging station that uses an RGB camera with a powerful image processing pipeline, to build a 3D representation of plants. The plant's constituent organs are detected and this detailed spatial data is available for further analysis.","img":"/assets/tools/plant-phenotyping/0-cover.png","docs":"https://docs.romi-project.eu/plant_imager/","body":{"type":"root","children":[{"type":"element","tag":"section-cover","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:title":""},"children":[{"type":"element","tag":"h1","props":{"id":"the-romi-plant-imager"},"children":[{"type":"text","value":"The ROMI Plant Imager"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The ROMI Plant Imager performs full 3D analyses of plants. It combines a physical scanning station that uses an RGB camera with a powerful image processing pipeline, the Plant Interpreter, to build a 3D representation of plants."}]},{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"base-embed","props":{"id":"b1HUAMF_Btg"},"children":[]}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/plant-phenotyping/1-plant-imager.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The ROMI project develops a 3D plant phenotyping platform adapted to single potted plants. The Plant Imager is being finalized in controlled indoor settings for a future use in research laboratories. However, its use in controlled farming environments, such as greenhouses, is envisioned as a mid-term application."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/plant-phenotyping/2-3d.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The interpreter currently detects plant constituent organs and this detailed spatial data is available for further analysis."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/plant-phenotyping/3-plant-3d-explorer.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The package consists of several modules, including:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"the Plant Imager: the physical hardware"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"the Virtual Plant Imager: to collect images of 3D plant models"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"the Plant 3D Vision: our library to analyse the data"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"the Plant 3D Explorer: to inspect the results online"}]}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/plant-phenotyping/4-plant-imager.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The analysis pipeline uses both geometrical algorithms and Machine Learning techniques. It is developed in collaboration with the research on "},{"type":"element","tag":"a","props":{"href":"/research/modeling"},"children":[{"type":"text","value":"plant modeling and AI"}]},{"type":"text","value":"."}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:2.tools:1.plant-phenotyping.md","_source":"content","_file":"2.tools/1.plant-phenotyping.md","_extension":"md"},{"_path":"/tools/crop-monitoring","_dir":"tools","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"The Farmer's Dashboard","description":"The Farmer's Dashboard and its associated device, the Cablebot, is our primary tool for crop monitoring. With the help of an aerial imaging device, images of the crop are collected and analysed to give the farmer an overview of the status of the crops and also of individual plants.","img":"/assets/tools/crop-monitoring/0-cover.png","docs":"https://docs.romi-project.eu/Farmers%20Dashboard/","body":{"type":"root","children":[{"type":"element","tag":"section-cover","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:title":""},"children":[{"type":"element","tag":"h1","props":{"id":"the-farmers-dashboard"},"children":[{"type":"text","value":"The Farmer's Dashboard"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The Farmer's Dashboard is a farming tool that provides daily automated insights about your crops. It helps with mapping of crop bed, the location, and identification of individual plants, and the extraction of their growth curves from the collected data. It is a set of hardware and software tools for affordable, customisable, and high frequency crop monitoring."}]},{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"base-embed","props":{"id":"g5bjv3CTZ-8"},"children":[]}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/crop-monitoring/1-farmers-dashboard.png"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The dashboard supports farmers with imaging and analytics that identify and track plant growth."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/crop-monitoring/2-monitoring-segmentation.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"After plants are detected, a catalogue of individual plants is created. By comparing them with historical data, we can obtain plant growth curves. All of the information is then combined into a weed map which is made available on the Farmers Dashboard website."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/crop-monitoring/3-cablebot.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Image data may be recieved from multiple sources, including drones, the rover, and cable bots. ROMI's Cable Bot is adapted for use in greenhouses, and polytunnels, and in situations where the use of a drone is not adapated."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/crop-monitoring/4-monitoring-orthomosaic.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Once set up, the ROMI Cable Bot will move multiple times a day across the crop bed, taking high definition images and sending them to a ROMI server. The images are assembled into a unique portrait of your crop bed."}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:2.tools:2.crop-monitoring.md","_source":"content","_file":"2.tools/2.crop-monitoring.md","_extension":"md"},{"_path":"/tools/weeding","_dir":"tools","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"The Rover for Weeding","description":"We designed the ROMI Rover as a farming tool to assist vegetable farmers in maintaining vegetable beds free of weeds. It does this by regularly hoeing the surface of the soil and thus preventing small weeds from taking root. It can do this task mostly autonomously and requires only minor changes to the organization of the farm.","img":"/assets/tools/weeding/0-cover.png","docs":"https://docs.romi-project.eu/Rover/","body":{"type":"root","children":[{"type":"element","tag":"section-cover","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:title":""},"children":[{"type":"element","tag":"h1","props":{"id":"the-romi-rover"},"children":[{"type":"text","value":"The ROMI Rover"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The ROMI Rover is a farming tool that assists vegetable farmers in maintaining vegetable beds free of weeds. It does this by regularly hoeing the surface of the soil and thus preventing small weeds from taking root. A weekly passage of the robot should be sufficient to keep the population of weeds under control."}]},{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"base-embed","props":{"id":"0-Focjjzc7k"},"children":[]}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/weeding/1-rover.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The ROMI Rover can perform the weeding task mostly autonomously and requires only minor changes to the organization of the farm. It is designed for vegetable beds between 70 cm and 120 cm wide (not including the passage ways) and for crops up to 50 cm high."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/weeding/2-lettuce.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"It currently handles two types of crops, lettuce and carrots. The lettuce can be planted out in any layout, most likely in a quincunx pattern. In this configuration the rover uses a precision rotary hoe to clean the soil both between the rows and the plants. This process is slower than classical mechanical weeding. The rover can cover up to 600 m²/day."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/weeding/3-carrots.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For carrots, the rover uses classical mechanical tools, such as stirrup hoe, to regularly clean the soil in between the rows. In this configuration, the carrots should be sown in line. In this classic configuration, the rover can cover a surface of 7200 m²/day."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/tools/weeding/4-vegetable-beds.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In addition to weeding, the embedded camera can be used to collect images of the vegetable beds. This images can be used by "},{"type":"element","tag":"a","props":{"href":"/tools/crop-monitoring"},"children":[{"type":"text","value":"the Farmer's Dashboard"}]},{"type":"text","value":"."}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:2.tools:3.weeding.md","_source":"content","_file":"2.tools/3.weeding.md","_extension":"md"},{"_path":"/research","_dir":"","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Research","description":"","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":""},"children":[{"type":"element","tag":"binding","props":{"value":"$doc.title"},"children":[]}]},{"type":"element","tag":"base-section","props":{},"children":[{"type":"element","tag":"section-grid","props":{"query":"/research"},"children":[]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:3.research:0.index.md","_source":"content","_file":"3.research/0.index.md","_extension":"md"},{"_path":"/research/modeling","_dir":"research","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Virtual plants and AI","description":"We use virtual plants to train neural networks. This allows us to detect plant organs without the need of collecting and annotating field data.","img":"/assets/research/modeling/0-cover.png","body":{"type":"root","children":[{"type":"element","tag":"section-cover","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:title":""},"children":[{"type":"element","tag":"h1","props":{"id":"plant-modeling-and-ai"},"children":[{"type":"text","value":"Plant modeling and AI"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We focus on the generation of synthetic ground truth data (images or point clouds) using virtual plant models, and on novel analysis techniques for 3D and 3D+time data."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/research/modeling/1-arabidopsis-model.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The work on the plant models has resulted in approved models for Arabidopsis thaliana and tomato plants. The model of A. thaliana was successfully used to train neural networks for the semantic segmentation of images of real plants and to produce high-quality point clouds for subsequent machine learning and analysis tasks."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/research/modeling/2-chenopodium-model.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This motivates the work to go further into the realistic rendering of plants and improve the physical coherence of the generated 3D plants. Existing state-of-the-art models, including ours, do not correctly detect and handle intersecting organs, for example. This problem is currently investigated together with other key issues related to photo-realistic rendering of plants."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/research/modeling/3-skeletons-zoom.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The challenge remains to robustly segment 3D plant data into its constituent organs can be tackled using several methods, from geometric methods to machine learning methods that use 2D image segmentation or 3D point cloud segmentation. An additional challenge is the precise extraction of the plant's skeleton from a 3D representation."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/research/modeling/4-arabidopsis.png"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Tracking the plant growth over time raises the issue on the space-time registration of the collected 3D data. The combination of plant models and machine learning may help us predict the plant's shape ahead of time."}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:3.research:1.modeling.md","_source":"content","_file":"3.research/1.modeling.md","_extension":"md"},{"_path":"/research/adaptive-systems","_dir":"research","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Adaptive systems","description":"Farming robots must be able to work in complex and variable environments. For example, plants are complex, time-varying objects. Outdoor fields are very uncontrolled environments, too.","img":"/assets/research/adaptive-systems/0-cover.png","body":{"type":"root","children":[{"type":"element","tag":"section-cover","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:title":""},"children":[{"type":"element","tag":"h1","props":{"id":""},"children":[{"type":"element","tag":"binding","props":{"value":"$doc.title"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We investigate advanced, open-ended learning techniques to gain insight in how farming robots can adapt their image processing capacities when facing plants on which they have not been trained, and insights in how they can learn to optimise the collection of visual information when facing complex plant scenes."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/research/adaptive-systems/1-curiosity.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We work on curiosity-driven goal-directed exploration behaviours to move an image sensor around a plant. The artificial curiosity system assigns interest values to pre-defined goals, and drives the exploration towards those that are expected to maximise the learning progress."}]}]},{"type":"element","tag":"section-split","props":{},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"dashboard screenshot","src":"/assets/research/adaptive-systems/2-rl.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We also train agents to move the camera using Reinforcement Learning. In this technique the agent has to learn how to map situations to actions so as to maximize a numerical reward. The learner is not told which actions to take, but instead has to discover which actions yield the most reward by trying them. In our case, the reward is derived from building an accurate 3D representation of a plant using a small number of images."}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:3.research:2.adaptive-systems.md","_source":"content","_file":"3.research/2.adaptive-systems.md","_extension":"md"},{"_path":"/topic-reports","_dir":"","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Topic Reports","description":"","showToc":false,"body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":""},"children":[{"type":"element","tag":"binding","props":{"value":"$doc.title"},"children":[]}]},{"type":"element","tag":"section-videos","props":{":items":"[{\"id\":\"hduQ5_xpyTI\",\"description\":\"Microfarms and computational agriculture: a future of farming?\"},{\"id\":\"_zkYwUczc0Q\",\"description\":\"The ROMI plaftorm: a helping hand to farming communities\"},{\"id\":\"E05uVM7FPIQ\",\"description\":\"Open source and open hardware: developing tools that are accessible and customisable\"}]"},"children":[{"type":"element","tag":"h2","props":{"id":"introduction-to-romi"},"children":[{"type":"text","value":"Introduction to ROMI"}]}]},{"type":"element","tag":"section-videos","props":{":items":"[{\"id\":\"a5oOR8Pfwzc\",\"description\":\"Plant developmental biology: how ROMI's tools help advance research in biology\"},{\"id\":\"rZk7tN9pUos\",\"description\":\"Data segmentation and analysis: developing algorithms to virtually dissect plants\"},{\"id\":\"Bo32_KI6SZ0\",\"description\":\"Synthetic plant modelling: creating plants in 3D to train neural networks\"}]"},"children":[{"type":"element","tag":"h2","props":{"id":"romi-and-biology-research"},"children":[{"type":"text","value":"ROMI and Biology Research"}]}]},{"type":"element","tag":"section-videos","props":{":items":"[{\"id\":\"VflubCtuyvc\",\"description\":\"Computer vision: algorithms to make sense of the world\"},{\"id\":\"YbByI0pGESY\",\"description\":\"Embodied AI: making robots curious\"}]"},"children":[{"type":"element","tag":"h2","props":{"id":"computer-vision-and-segmentation"},"children":[{"type":"text","value":"Computer Vision and Segmentation"}]}]},{"type":"element","tag":"section-videos","props":{":items":"[{\"id\":\"7aKQSbrldc0\",\"description\":\"Tell me more: a deeper dive into the ROVER\"},{\"id\":\"IVo6hM8GWWQ\",\"description\":\"Tell me more: a deeper dive into the CABLEBOT\"},{\"id\":\"w_AxsZlTkyA\",\"description\":\"Tell me more: a deeper dive into the PLANT IMAGER\"},{\"id\":\"_3oiv_96-X8\",\"description\":\"Tell me more: a deeper dive into FARMER'S DASHBOARD\"},{\"id\":\"CTOhDddCxvE\",\"description\":\"Software tools used in ROMI: a quick look into some of the tools used to develop ROMI\"}]"},"children":[{"type":"element","tag":"h2","props":{"id":"the-romi-tools-in-depth"},"children":[{"type":"text","value":"The ROMI tools in depth"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"introduction-to-romi","depth":2,"text":"Introduction to ROMI"},{"id":"romi-and-biology-research","depth":2,"text":"ROMI and Biology Research"},{"id":"computer-vision-and-segmentation","depth":2,"text":"Computer Vision and Segmentation"},{"id":"the-romi-tools-in-depth","depth":2,"text":"The ROMI tools in depth"}]}},"_type":"markdown","_id":"content:4.topic-reports.md","_source":"content","_file":"4.topic-reports.md","_extension":"md"},{"_path":"/training","_dir":"","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Training","description":"","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":""},"children":[{"type":"element","tag":"binding","props":{"value":"$doc.title"},"children":[]}]},{"type":"element","tag":"section-videos","props":{":items":"[{\"id\":\"534lryjLib0\",\"description\":\"1  General Intro   Creating Virtual Plants with L systems training\"},{\"id\":\"LZjne2iP5iI\",\"description\":\"2  Part 1   Basic Botanical Principles   Creating Virtual Plants with L systems training\"},{\"id\":\"s0r6N1t3Pdw\",\"description\":\"3  Part 2   Modelling Plant Growth   Conceptual Aspects   1:3   Creating Virtual Plants with L syste\"},{\"id\":\"WjL_egTwZKU\",\"description\":\"4  Part 2   Modelling Plant Growth   Conceptual Aspects   2:3   Creating Virtual Plants with L syste\"},{\"id\":\"ps7Mt1y1F48\",\"description\":\"5  Part 2   Modelling Plant Growth   Conceptual Aspects   3:3   Creating Virtual Plants with L syste\"},{\"id\":\"pd6t8K1uVTQ\",\"description\":\"6  Part 3   L systems Programming   Basic concepts   1:2   Creating Virtual Plants with L systems tr\"},{\"id\":\"GP8R1nxddk4\",\"description\":\"7  Part 3   L systems Programming   Basic concepts   2:2   Creating Virtual Plants with L systems tr\"},{\"id\":\"a69EnrXG-e4\",\"description\":\"8  Part 3   L systems Programming   Advanced features   Creating Virtual Plants with L systems train\"},{\"id\":\"FDlgFqLXuz4\",\"description\":\"9  Part 4   Modelling Plant Growth   Simple Architectural Processes   1:3   Creating Virtual Plants\"},{\"id\":\"pYQSut5xnYo\",\"description\":\"10  Part 4  Modelling Plant Growth   Simple Architectural Processes   2:3   Creating Virtual Plants\"},{\"id\":\"c8ThIYQ1W_g\",\"description\":\"11  Part 4  Modelling Plant Growth   Simple Architectural Processes   3:3   Creating Virtual Plants\"},{\"id\":\"ux7UshXpAsg\",\"description\":\"12  Part 4   Modelling Plant Growth   Advanced Topics   Creating Virtual Plants with L systems train\"},{\"id\":\"_HkPs_sBLNQ\",\"description\":\"13  Part 4   Modelling Plant Growth   Coordination and Organ Growth   Creating Virtual Plants with L\"},{\"id\":\"W7WX5O6qg1M\",\"description\":\"14  Part 5  L systems Programming with L Py   Using Notebooks   Creating Virtual Plants with L syste\"},{\"id\":\"K_68cTcUJAA\",\"description\":\"15  Part 5  L systems Programming with L Py   L Py Tools   Creating Virtual Plants with L systems tr\"},{\"id\":\"rh9_dtniOz4\",\"description\":\"16  Part 6  Measuring plant phenotypes   Creating Virtual Plants with L systems training\"},{\"id\":\"AXmXCSWWyyU\",\"description\":\"17  Part 7  Virtual Plants for Machine Learning Part 1:2   Creating Virtual Plants with L systems tr\"},{\"id\":\"nzTe1zlXqrE\",\"description\":\"18  Part 7  Virtual Plants for Machine Learning Part 2:2   Creating Virtual Plants with L systems tr\"},{\"id\":\"90AnJQ52FTk\",\"description\":\"19  Practical training   Definition of Projects   Creating Virtual Plants with L systems training\"},{\"id\":\"fPdNX1tDLY8\",\"description\":\"20  Practical training   Presentation of Projects Intermidiate Step   Creating Virtual Plants with L\"},{\"id\":\"HXI_VF-51YI\",\"description\":\"21  Practical training   Presentation of Final Projects   Creating Virtual Plants with L systems tra\"}]"},"children":[{"type":"element","tag":"h2","props":{"id":"master-class-creating-virtual-plants"},"children":[{"type":"text","value":"Master Class: Creating Virtual Plants"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"master-class-creating-virtual-plants","depth":2,"text":"Master Class: Creating Virtual Plants"}]}},"_type":"markdown","_id":"content:5.training.md","_source":"content","_file":"5.training.md","_extension":"md"},{"_path":"/downloads","_dir":"","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Downloads","description":"","showToc":true,"body":{"type":"root","children":[{"type":"element","tag":"base-prose","props":{"class":"!max-w-none"},"children":[{"type":"element","tag":"h1","props":{"id":"list-of-public-deliverables-papers-documents-and-datasets"},"children":[{"type":"text","value":"List of public deliverables, papers, documents, and datasets"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"All material on this page is licensed under the "},{"type":"element","tag":"a","props":{"href":"https://creativecommons.org/licenses/by/4.0/","rel":["nofollow"]},"children":[{"type":"text","value":"Creative Commons CC BY 4.0 International"}]},{"type":"text","value":" license unless noted otherwise."}]},{"type":"element","tag":"h2","props":{"id":"general"},"children":[{"type":"text","value":"General"}]},{"type":"element","tag":"h3","props":{"id":"vision-and-scenarios"},"children":[{"type":"text","value":"Vision and scenarios"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-Vision_and_Scenarios-1.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-Vision_and_Scenarios-1.pdf\"}]","title":"Vision and scenarios"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This document gives a view of our long-term vision and how the results of the different work packages come together in concrete scenarios."}]}]},{"type":"element","tag":"h2","props":{"id":"deliverables"},"children":[{"type":"text","value":"Deliverables"}]},{"type":"element","tag":"h3","props":{"id":"wp1-management"},"children":[{"type":"text","value":"WP1 - Management"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D1.1-IPR_Strategic_Plan.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D1.1-IPR_Strategic_Plan.pdf\"},{\"label\":\"Annexes\",\"link\":\"https://media.romi-project.eu/documents/D1.1/\"}]","title":"D1.1 - IPR Strategic Plan","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"ROMI's IPR strategy is based on an open-software/open-hardware model. In this document we give a more in-depth description of this approach. We present a bibliographic study and look at some of the related business models."}]}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D1.2-Management-document_-_The-Rover.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D1.2-Management-document_-_The-Rover.pdf\"}]","title":"D1.2 - The Romi Rover - Project Management","badge":"Reporting period 2"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This document covers the status of the Romi Rover, including the usage scenario, the development progress, the specifications, the user studies, market studies, and a draft user manual."}]}]},{"type":"element","tag":"h3","props":{"id":"wp2-robot-for-weeding-and-detailed-crop-monitoring"},"children":[{"type":"text","value":"WP2 - Robot for weeding and detailed crop monitoring"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D2.1-First_LettuceThink_Prototype.mp4\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D2.1-First_LettuceThink_Prototype.mp4\"},{\"label\":\"ROMI-D2.1-First_LettuceThink_Prototype.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D2.1-First_LettuceThink_Prototype.pdf\"},{\"label\":\"Design files\",\"link\":\"https://media.romi-project.eu/documents/D2.1/Design\"},{\"label\":\"Photos\",\"link\":\"https://media.romi-project.eu/documents/D2.1/Photos\"},{\"label\":\"Videos\",\"link\":\"https://media.romi-project.eu/documents/D2.1/Videos\"},{\"label\":\"Visuals\",\"link\":\"https://media.romi-project.eu/documents/D2.1/Visuals\"}]","title":"D2.1 - First LettuceThink prototype","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This demonstrator shows the first prototype of LettuceThink in action. The accompanying documents provides the technical details."}]}]},{"type":"element","tag":"h3","props":{"id":"wp3-drone-for-aerial-crop-monitoring"},"children":[{"type":"text","value":"WP3 - Drone for aerial crop monitoring"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D3.1-First_NERO_Prototype.mp4\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D3.1-First_NERO_Prototype.mp4\"},{\"label\":\"ROMI-D3.1-First_NERO_Prototype.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D3.1-First_NERO_Prototype.pdf\"},{\"label\":\"Design files\",\"link\":\"https://media.romi-project.eu/documents/D3.1/Design\"},{\"label\":\"Photos\",\"link\":\"https://media.romi-project.eu/documents/D3.1/Photos\"},{\"label\":\"Videos\",\"link\":\"https://media.romi-project.eu/documents/D3.1/Videos\"},{\"label\":\"Visuals\",\"link\":\"https://media.romi-project.eu/documents/D3.1/Visuals\"}]","title":"D3.1 - First NERO prototype","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This demonstrator shows the first prototype of air-borne device. The accompanying documents shed light on the design decisions and the technical details of the current solution."}]}]},{"type":"element","tag":"h3","props":{"id":"wp4-adaptive-learning-for-the-coordinated-control-of-sensors-and-actuators"},"children":[{"type":"text","value":"WP4 - Adaptive learning for the coordinated control of sensors and actuators"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The goal of the work in WP4 system is to improve the 3D reconstruction of the plants by generating robot movements that optimise the information obtained by the camera sensors."}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D4.1-Report_Experimental_Set-up_Adaptive_Learning.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D4.1-Report_Experimental_Set-up_Adaptive_Learning.pdf\"},{\"label\":\"D5.1/SegmentationDataset/\",\"link\":\"https://media.romi-project.eu/documents/D5.1/SegmentationDataset/\"}]","title":"D4.1 - Report on the experimental set-up of the adaptive learning system","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"During the first reporting period, we have developed and tested a first prototype of the system and describe the set-up, its software and its hardware components."}]}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D4.2-Report-on-the-adaptive-learning-system.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D4.2-Report-on-the-adaptive-learning-system.pdf\"},{\"label\":\"ROMI-D4.2-whiskers_close.mp4\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D4.2-whiskers_close.mp4\"},{\"label\":\"ROMI-D4.2-whiskers.mp4\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D4.2-whiskers.mp4\"},{\"label\":\"ROMI-D4.2-env1_model1.mp4\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D4.2-env1_model1.mp4\"},{\"label\":\"ROMI-D4.2-env2_model1.mp4\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D4.2-env2_model1.mp4\"},{\"label\":\"ROMI-D4.2-env3_model1.mp4\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D4.2-env3_model1.mp4\"}]","title":"D4.2 Intermediate report on the theoretical advances and the experimental results of the adaptive learning system","badge":"Reporting period 2"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"During the first reporting period, we have developed and tested a first prototype of the system and describe the set-up, its software and its hardware components."}]}]},{"type":"element","tag":"h3","props":{"id":"wp5-advanced-sensing-and-analysis-of-crops"},"children":[{"type":"text","value":"WP5 - Advanced sensing and analysis of crops"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D5.1-Demonstration_3D_Image_Segmentation_Weeding.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D5.1-Demonstration_3D_Image_Segmentation_Weeding.pdf\"}]","title":"D5.1 - Demonstration of a 3d image segmentation application for weeding","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This deliverable cover the progress on the machine vision and machine learning algorithms, both of which are used in the automatic weeding application of the LettuceThink robot described in D2.1 above."}]}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D5.3-Demonstration_3D_Reconstruction_Plants.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D5.3-Demonstration_3D_Reconstruction_Plants.pdf\"},{\"label\":\"Demo 3D plant reconstructions\",\"link\":\"https://media.romi-project.eu/documents/D5.3/Demo_Plant-3D-Reconstructions/\"},{\"label\":\"Demo 3D scans and database structure\",\"link\":\"https://media.romi-project.eu/documents/D5.3/scans/\"}]","title":"D5.3 - Demonstration of indoor and outdoor, 3d reconstruction of plants"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This deliverable cover the progress on the machine vision and machine learning algorithms, both of which are used in the automatic weeding application of the LettuceThink robot described in D2.1 above."}]}]},{"type":"element","tag":"h3","props":{"id":"wp6-plant-modelling"},"children":[{"type":"text","value":"WP6 - Plant modelling"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The ROMI project develops a toolbox for plant scanning and analysis that combines different approaches. In WP6 we develop an approach that is heavily based on plant models. These models are used as a support for the data analysis and plant segmentation but also as a source for synthetic images used to train neural networks."}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D6.1-Simplified_Model_Arabidopsis.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D6.1-Simplified_Model_Arabidopsis.pdf\"},{\"label\":\"ROMI-D6.1-Simplified_Model_Arabidopsis.avi\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D6.1-Simplified_Model_Arabidopsis.avi\"}]","title":"D6.1 - Simplified model of Arabidopsis thaliana","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"During the first reporting period, we developed a model of the Arabidopsis thaliana, which is also used in WP5 to evaluate the scanning algorithms."}]}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D6.2-Model-of-crop-species-1.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D6.2-Model-of-crop-species-1.pdf\"},{\"label\":\"Tomato, movie 1\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D6.2-Tomato-4-seed16-25fps.avi\"},{\"label\":\"Tomato, movie 2\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D6.2-Tomato-4-seed17-20fps.avi\"},{\"label\":\"A. thaliana, movie 1\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D6.2-Arabidopsis-WT-20fps.avi\"},{\"label\":\"A. thaliana, movie 2\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D6.2-Arabidopsis-WT-above-20fps.avi\"}]","title":"D6.2 - Model of crop species #1","badge":"Reporting period 2"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"During the second reporting period, we developed a first model of a crop species, notably the tomato plant. An improved version of the "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"A. thaliana"}]},{"type":"text","value":" model, with improved rendering, is also discussed."}]}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D6.3-Results-of-trained-models.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D6.3-Results-of-trained-models.pdf\"}]","title":"D6.3 - Results of trained models","badge":"Reporting period 2"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This document the results we obtained by using the model of "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"A.thaliana"}]},{"type":"text","value":" developed above to train neural networks to segment images of real "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"A. thaliana"}]},{"type":"text","value":" plants."}]}]},{"type":"element","tag":"h3","props":{"id":"wp7-data-acquisition-and-real-world-application-testing"},"children":[{"type":"text","value":"WP7 - Data acquisition and real-world application testing"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D7.1-Description_Experimental_Set-up_Outdoor_Field_Studies.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D7.1-Description_Experimental_Set-up_Outdoor_Field_Studies.pdf\"},{\"label\":\"Annexes\",\"link\":\"https://media.romi-project.eu/documents/D7.1/\"}]","title":"D7.1 - Description of the experimental set-up of the outdoor field studies","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"ROMI conducts field studies in two outdoor locations: at Chatelain Maraîchage, nord of Paris, and at Valldaura, in the hills above Barcelona. In D7.1 you will find an overview of both locations and the work that has been done to prepare for the field studies."}]}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D7.2-Intermediate_Report_Field_Studies-1.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D7.2-Intermediate_Report_Field_Studies-1.pdf\"},{\"label\":\"Annexes\",\"link\":\"https://media.romi-project.eu/documents/D7.2/\"},{\"label\":\"Scans Session 1 (RGB)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-10m-2-2-photoscan-RGB-DJI.html\"},{\"label\":\"Scans Session 1 (NDVI)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-10m-2-2-photoscan-NDVI-MOBIUS.html\"},{\"label\":\"Scans Session 1 (NIR)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-10m-2-2-photoscan-NIR-MOBIUS.html\"},{\"label\":\"Scans Session 2 (RGB)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-13m-1-1-photoscan--RGB-DJI.html\"},{\"label\":\"Scans Session 2 (NDVI)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-13m-1-1-photoscan-NDVI-MOBIUS.html\"},{\"label\":\"Scans Session 2 (NIR)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-13m-1-1-photoscan-NIR-MOBIUS.html\"}]","title":"D7.2 - Intermediate report on the field studies I","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This document is the continuation of D7.1. It presents the results of the field studies that have been performed during the first season of the project."}]}]},{"type":"element","tag":"h3","props":{"id":"wp8-dissemination-and-exploitation"},"children":[{"type":"text","value":"WP8 - Dissemination and exploitation"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D8.1-Data_Management_Plan.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D8.1-Data_Management_Plan.pdf\"}]","title":"D8.1 - Data Management Plan","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"A detailed overview of how we plan to make our data available (design files, source code, data sets…)."}]}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D8.2-Intermediate_Dissemination_Report_I.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D8.2-Intermediate_Dissemination_Report_I.pdf\"},{\"label\":\"Brand Book + Design Assets\",\"link\":\"https://media.romi-project.eu/documents/D8.2/ROMI-Asset_Download\"},{\"label\":\"Brand Guidelines\",\"link\":\"https://media.romi-project.eu/documents/D8.2/ROMI-Brand_Guidelines.pdf\"},{\"label\":\"Flyer 1 - Rover\",\"link\":\"https://media.romi-project.eu/documents/D8.2/2018_12_03-ROMI-Flyer_Rover.pdf\"},{\"label\":\"Flyer 2 - Drone\",\"link\":\"https://media.romi-project.eu/documents/D8.2/2018_09_17_ROMI-Flyer_Drone.pdf\"},{\"label\":\"Strategic Presentation\",\"link\":\"https://media.romi-project.eu/documents/D8.2/ROMI-WP8_Communications.pdf\"},{\"label\":\"Public Presentation\",\"link\":\"https://media.romi-project.eu/documents/D8.2/20180807-ROMI-Specific_Review.pdf\"},{\"label\":\"Market study\",\"link\":\"https://media.romi-project.eu/documents/D8.2/ROMI-Market_study-21122018.pdf\"},{\"label\":\"Technology watch (1)\",\"link\":\"https://media.romi-project.eu/documents/D8.2/ROMI-Technological_watch_21122018.pdf\"},{\"label\":\"Technology watch (2)\",\"link\":\"https://media.romi-project.eu/documents/D8.2/ROMI-Technological_watch_V2.pdf\"},{\"label\":\"Legislation on robots and drones\",\"link\":\"https://media.romi-project.eu/documents/D8.2/Legislation_robots_and_drones.docx\"},{\"label\":\"Table on legislation on drones in the EU\",\"link\":\"https://media.romi-project.eu/documents/D8.2/ROMI-National_regulations_drones.xlsx\"}]","title":"D8.2 - Intermediate dissemination report I","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We have had many opportunities to present ROMI both toward the general public as to a professional audience. The details can be found in this deliverable. In addition, we (SONY, FEI, IAAC under the coordination of FEI) worked on several studies (not planned in the original grant agreement) with the goal to better understand the markets of planned ROMI results (European vegetable microfarms) and our competitors (technologies, companies)."}]}]},{"type":"element","tag":"h3","props":{"id":"wp9"},"children":[{"type":"text","value":"WP9"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"ROMI-D9.1-Ethics_Document.pdf\",\"link\":\"https://media.romi-project.eu/documents/ROMI-D9.1-Ethics_Document.pdf\"}]","title":"D9.1 - POPD - Requirement No. 1","badge":"Reporting period 1"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The document on the Protection of Personal Data, part of the Ethics Requirements."}]}]},{"type":"element","tag":"h2","props":{"id":"datasets"},"children":[{"type":"text","value":"Datasets"}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"D5.1/SegmentationDataset/\",\"link\":\"https://media.romi-project.eu/documents/D5.1/SegmentationDataset/\"}]","title":"Segmentation dataset"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The segmentation dataset for radishes. See als deliverable D5.1."}]}]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"Scans Session 1 (RGB)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-10m-2-2-photoscan-RGB-DJI.html\"},{\"label\":\"Scans Session 1 (NDVI)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-10m-2-2-photoscan-NDVI-MOBIUS.html\"},{\"label\":\"Scans Session 1 (NIR)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-10m-2-2-photoscan-NIR-MOBIUS.html\"},{\"label\":\"Scans Session 2 (RGB)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-13m-1-1-photoscan--RGB-DJI.html\"},{\"label\":\"Scans Session 2 (NDVI)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-13m-1-1-photoscan-NDVI-MOBIUS.html\"},{\"label\":\"Scans Session 2 (NIR)\",\"link\":\"https://media.romi-project.eu/data/valldaura/pointclouds/181117-13m-1-1-photoscan-NIR-MOBIUS.html\"}]","title":"Point clouds of Can Valldaura"},"children":[]},{"type":"element","tag":"base-download","props":{":downloads":"[{\"label\":\"Demo 3D plant reconstructions\",\"link\":\"https://media.romi-project.eu/documents/D5.3/Demo_Plant-3D-Reconstructions/\"},{\"label\":\"Demo 3D scans and database structure\",\"link\":\"https://media.romi-project.eu/documents/D5.3/scans/\"}]","title":"3D plant scans"},"children":[]},{"type":"element","tag":"h2","props":{"id":"license-abbreviations"},"children":[{"type":"text","value":"License abbreviations"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"CC-BY-4.0: "},{"type":"element","tag":"a","props":{"href":"https://creativecommons.org/licenses/by/4.0/","rel":["nofollow"]},"children":[{"type":"text","value":"Creative Commons CC BY 4.0 International"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"LGPLv3: "},{"type":"element","tag":"a","props":{"href":"https://www.gnu.org/licenses/lgpl-3.0.en.html","rel":["nofollow"]},"children":[{"type":"text","value":"GNU Lesser General Public License, version 3"}]}]}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"general","depth":2,"text":"General","children":[{"id":"vision-and-scenarios","depth":3,"text":"Vision and scenarios"}]},{"id":"deliverables","depth":2,"text":"Deliverables","children":[{"id":"wp1-management","depth":3,"text":"WP1 - Management"},{"id":"wp2-robot-for-weeding-and-detailed-crop-monitoring","depth":3,"text":"WP2 - Robot for weeding and detailed crop monitoring"},{"id":"wp3-drone-for-aerial-crop-monitoring","depth":3,"text":"WP3 - Drone for aerial crop monitoring"},{"id":"wp4-adaptive-learning-for-the-coordinated-control-of-sensors-and-actuators","depth":3,"text":"WP4 - Adaptive learning for the coordinated control of sensors and actuators"},{"id":"wp5-advanced-sensing-and-analysis-of-crops","depth":3,"text":"WP5 - Advanced sensing and analysis of crops"},{"id":"wp6-plant-modelling","depth":3,"text":"WP6 - Plant modelling"},{"id":"wp7-data-acquisition-and-real-world-application-testing","depth":3,"text":"WP7 - Data acquisition and real-world application testing"},{"id":"wp8-dissemination-and-exploitation","depth":3,"text":"WP8 - Dissemination and exploitation"},{"id":"wp9","depth":3,"text":"WP9"}]},{"id":"datasets","depth":2,"text":"Datasets"},{"id":"license-abbreviations","depth":2,"text":"License abbreviations"}]}},"_type":"markdown","_id":"content:6.downloads.md","_source":"content","_file":"6.downloads.md","_extension":"md"},{"_path":"/about","_dir":"","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"About","description":"","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"about-us"},"children":[{"type":"text","value":"About us"}]},{"type":"element","tag":"base-section","props":{},"children":[{"type":"element","tag":"section-split-hero","props":{"class":"!p-0 !items-start !min-h-0 !border-none"},"children":[{"type":"element","tag":"template","props":{"v-slot:left":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"ROMI is a four-year Europe-funded research project committed to promote a sustainable, local, and human-scale agriculture. The goal is to develop an open-source, affordable, multipurpose platform adapted to support organic and poly-culture market-garden farms."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Small, diversified vegetable farms have an important role to play in sustainable food production. Installed close to cities, they provide healthy vegetables at accessible prices through short supply chains. They contribute to the biodiversity in peri-urban areas and re-establish the missing link between urban and rural areas."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The Robotics for Microfarms project (ROMI) looks at the use of new technology, including robotics, AI, and advanced modeling, to assist these farms."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The sizes of the farms that we are addressing are between 1000 m² and five hectares. These farms grow a large number of vegetables, up to a hundred varieties, every season. Because of this complexity, most of the planting out, weeding, and harvesting is performed manually. This work is quite physical and time consuming. The ROMI project looks at how new technologies can aid these farmers. The solutions must be adapted to the constraints imposed by these farms (small size, many different crops, lower investment capacity). The ROMI project therefore proposes technologies that are inexpensive, light-weight, and adaptable."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We are looking both at concrete technologies for short-term applications as well as research for more long-term requirements. In the short term, we look at automatic weeding and crop monitoring for more precise crop planning. In the longer term, we deal with 3D imaging and modeling of individual plants for detailed plant health analysis and selective plant breeding. We also look into adative robotics so that our tools can deal gracefully with the complex, time-varying, in-field conditions."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The ROMI technologies are available under an Open Source license in the hope of reaching as many microfarms as possible. We are currently targeting the European microfarms but we keep in mind that worldwide there are over 500 million small-holder farms that could benefit from our work."}]}]},{"type":"element","tag":"template","props":{"v-slot:right":""},"children":[{"type":"element","tag":"base-card","props":{"variant":"primary"},"children":[{"type":"element","tag":"template","props":{"v-slot:media":""},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"The ROMI team celebrating the publication of the project.","src":"/assets/about-team.jpg"},"children":[]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Have any questions or comments you'd like to share with us? Please feel free to reach out at "},{"type":"element","tag":"a","props":{"href":"mailto:info@romi-project.eu"},"children":[{"type":"text","value":"info@romi-project.eu"}]},{"type":"text","value":"."}]}]}]}]}]},{"type":"element","tag":"h2","props":{"id":"romi-partners"},"children":[{"type":"text","value":"ROMI Partners"}]},{"type":"element","tag":"site-partners","props":{},"children":[]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"romi-partners","depth":2,"text":"ROMI Partners"}]}},"_type":"markdown","_id":"content:8.about.md","_source":"content","_file":"8.about.md","_extension":"md"},{"_path":"/partners/iaac","_dir":"partners","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"IAAC Fab Lab Barcelona","description":"Fab Lab Barcelona at IAAC develops an aerial robot that can be used by farmers. It also performs real-world tests in the experimental gardens at the Valldaura Labs and the Benifallet Ecological Rural Lab (BER-LAB) to imagine end-user scenarios. They help deliver the robotics platform to new markets, managing the communication and user communities.","url":"https://fablabbcn.org/","logo":"/assets/partners/iaac.png","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Fab Lab Barcelona at IAAC develops an aerial robot that can be used by farmers. It also performs real-world tests in the experimental gardens at the Valldaura Labs and the Benifallet Ecological Rural Lab (BER-LAB) to imagine end-user scenarios. They help deliver the robotics platform to new markets, managing the communication and user communities."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:9.partners:1.iaac.md","_source":"content","_file":"9.partners/1.iaac.md","_extension":"md"},{"_path":"/partners/sony","_dir":"partners","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Sony CSL","description":"Sony CSL is responsible for the development of the weeding robot. They also contribute to the development of the computer vision and machine learning algorithms, in particular, on the 3D plant imaging and the coupling between the formal plant models and the convolutional neural networks.","url":"https://csl.sony.fr/projects-sustainability/","logo":"/assets/partners/sony-csl.png","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Sony CSL is responsible for the development of the weeding robot. They also contribute to the development of the computer vision and machine learning algorithms, in particular, on the 3D plant imaging and the coupling between the formal plant models and the convolutional neural networks."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:9.partners:2.sony.md","_source":"content","_file":"9.partners/2.sony.md","_extension":"md"},{"_path":"/partners/virtual-plants","_dir":"partners","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Virtual Plants","description":"The Virtual Plants team brings its strong expertise in the area of 3D plant architecture reconstruction and modelling. Notably, the team develops computer pipelines to reconstruct plant architecture from 3D data, to assess their reconstruction, and to segment the architecture in its constituent organs.","url":"https://www.inria.fr/equipes/mosaic","logo":"/assets/partners/inria.svg","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The Virtual Plants team brings its strong expertise in the area of 3D plant architecture reconstruction and modelling. Notably, the team develops computer pipelines to reconstruct plant architecture from 3D data, to assess their reconstruction, and to segment the architecture in its constituent organs."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:9.partners:3.virtual-plants.md","_source":"content","_file":"9.partners/3.virtual-plants.md","_extension":"md"},{"_path":"/partners/adaptive-systems","_dir":"partners","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Adaptive Systems","description":"The Adaptive Systems Group expertise lies in models for closed-loop learning and prediction of sensorimotor data, as well as behaviour recognition and generation. The tasks planned will focus on the learning and adaptive techniques for the interaction between robots and plants.","url":"https://adapt.informatik.hu-berlin.de/","logo":"/assets/partners/as.jpeg","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The Adaptive Systems Group expertise lies in models for closed-loop learning and prediction of sensorimotor data, as well as behaviour recognition and generation. The tasks planned will focus on the learning and adaptive techniques for the interaction between robots and plants."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:9.partners:4.adaptive-systems.md","_source":"content","_file":"9.partners/4.adaptive-systems.md","_extension":"md"},{"_path":"/partners/rdp","_dir":"partners","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"RDP","description":"The RDP team has a deep understanding of the development and evolution of plant reproductive systems. RDP leads the advanced sensing and analysis of crops, and brings its expertise on the developmental dynamics and modelling of plant architecture.","url":"http://www.ens-lyon.fr/RDP/","logo":"/assets/partners/rdp.jpg","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The RDP team has a deep understanding of the development and evolution of plant reproductive systems. RDP leads the advanced sensing and analysis of crops, and brings its expertise on the developmental dynamics and modelling of plant architecture."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:9.partners:5.rdp.md","_source":"content","_file":"9.partners/5.rdp.md","_extension":"md"},{"_path":"/partners/pepinieres-chatelain","_dir":"partners","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Pépinières Chatelain","description":"Chatelain Pépinières runs a commercial market farm near Paris. They perform field studies to test the efficiency of the weeding robot and the usefulness of the crop monitoring applications in real-world situations.","url":"https://www.pepinieres-chatelain.com/","logo":"/assets/partners/pepipnieres-chatelain.png","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Chatelain Pépinières runs a commercial market farm near Paris. They perform field studies to test the efficiency of the weeding robot and the usefulness of the crop monitoring applications in real-world situations."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:9.partners:6.pepinieres-chatelain.md","_source":"content","_file":"9.partners/6.pepinieres-chatelain.md","_extension":"md"},{"_path":"/partners/fei","_dir":"partners","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"FEI","description":"FEI provides assistance and training for projects partly funded by the European Commission, as coordinator or as partner. FEI intervenes close to them in the administrative, financial coordination and management of their projects.","url":"https://www.france-europe-innovation.fr/","logo":"/assets/partners/fei.jpg","navigation":false,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"FEI provides assistance and training for projects partly funded by the European Commission, as coordinator or as partner. FEI intervenes close to them in the administrative, financial coordination and management of their projects."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:9.partners:7.fei.md","_source":"content","_file":"9.partners/7.fei.md","_extension":"md"}],"navigation":[{"title":"Home","_path":"/"},{"title":"Tools","_path":"/tools","children":[{"title":"The Plant Imager","_path":"/tools/plant-phenotyping"},{"title":"The Farmer's Dashboard","_path":"/tools/crop-monitoring"},{"title":"The Rover for Weeding","_path":"/tools/weeding"}]},{"title":"Research","_path":"/research","children":[{"title":"Virtual plants and AI","_path":"/research/modeling"},{"title":"Adaptive systems","_path":"/research/adaptive-systems"}]},{"title":"Topic Reports","_path":"/topic-reports"},{"title":"Training","_path":"/training"},{"title":"Downloads","_path":"/downloads"},{"title":"About","_path":"/about"}]}